{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9017e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d39d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "benf=pd.read_csv('../data/Train_Beneficiarydata-1542865627584.csv')\n",
    "benf.head(10)\n",
    "#dob- date of birth\n",
    "#dod- date of death- missing value might endicate the person is alive\n",
    "#dentaldiseaseind- often require expensive treatments \n",
    "#NoOfMonths_PartACovered- number of months the beneficiary was covered under part A: Submit claims during months when the patient was NOT covered\n",
    "### financial coverage features:\n",
    "#IPAnnualReimbursementAmt-> total amount of money medicalcare provided for inpatients(hospital stays, surgeries, emergency admissions, long-term recovery stays) services\n",
    "#IPAnnualDeductibleAmt-> total amount the patient paid themselves (deductibles) for inpatient services\n",
    "#OPAnnualReimbursementAmt-> total amount of money medicalcare provided for outpatient (doctor visits, lab tests, therapies, preventive care) services\n",
    "#OPAnnualDeductibleAmt-> total amount the patient paid themselves (deductibles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d49b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpatient=pd.read_csv('../data/Train_Inpatientdata-1542865627584.csv')\n",
    "inpatient.head(10)\n",
    "#DischargeDt-Should align with ClaimEndDt. used to compute length of hospital stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dfbc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "outpatient=pd.read_csv('../data/Train_Outpatientdata-1542865627584.csv')\n",
    "outpatient.head(10)\n",
    "#ClmAdmitDiagnosisCode-Primary diagnosis code when the outpatient service was requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba01ae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "benf.drop_duplicates()\n",
    "inpatient.drop_duplicates()\n",
    "outpatient.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2883d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load test\n",
    "benf_test=pd.read_csv('../data/Test_Beneficiarydata-1542969243754.csv')\n",
    "inpatient_test=pd.read_csv('../data/Test_Inpatientdata-1542969243754.csv')  \n",
    "outpatient_test=pd.read_csv('../data/Test_Outpatientdata-1542969243754.csv')\n",
    "test_id=pd.read_csv('../data/Test-1542969243754.csv')\n",
    "benf_test.drop_duplicates()\n",
    "inpatient_test.drop_duplicates()\n",
    "outpatient_test.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68806ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Beneficiary Table\n",
    "\n",
    "# Beneficiary Table\n",
    "benf['DOB'] = pd.to_datetime(benf['DOB'], errors='coerce')\n",
    "benf['DOD'] = pd.to_datetime(benf['DOD'], errors='coerce')\n",
    "\n",
    "#add age attribute and is alive attribute\n",
    "benf['is_alive'] = benf['DOD'].isna().astype(int)\n",
    "benf['age'] = ((benf['DOD'].fillna(pd.Timestamp.today()) - benf['DOB']).dt.days / 365.25).astype(int)\n",
    "\n",
    "# Check result\n",
    "benf[['DOB', 'DOD', 'is_alive', 'age']].head()\n",
    "\n",
    "#testing:\n",
    "\n",
    "benf_test['DOB'] = pd.to_datetime(benf_test['DOB'], errors='coerce')\n",
    "benf_test['DOD'] = pd.to_datetime(benf_test['DOD'], errors='coerce')\n",
    "\n",
    "#add age attribute and is alive attribute\n",
    "benf_test['is_alive'] = benf_test['DOD'].isna().astype(int)\n",
    "benf_test['age'] = ((benf_test['DOD'].fillna(pd.Timestamp.today()) - benf_test['DOB']).dt.days / 365.25).astype(int)\n",
    "\n",
    "# Check result\n",
    "benf_test[['DOB', 'DOD', 'is_alive', 'age']].head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5381083",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inpatient\n",
    "date_cols = inpatient.columns[inpatient.columns.str.contains('Dt|Date', case=False)]\n",
    "for col in date_cols:\n",
    "    inpatient[col] = pd.to_datetime(inpatient[col], errors='coerce')\n",
    "inpatient.isnull().sum()\n",
    "#test:\n",
    "date_cols = inpatient_test.columns[inpatient_test.columns.str.contains('Dt|Date', case=False)]\n",
    "for col in date_cols:\n",
    "    inpatient_test[col] = pd.to_datetime(inpatient_test[col], errors='coerce')\n",
    "inpatient_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5656c0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of diagnosis and procedure columns\n",
    "diagnosis_cols = [f'ClmDiagnosisCode_{i}' for i in range(1, 10)]\n",
    "procedure_cols = [f'ClmProcedureCode_{i}' for i in range(1, 6)]\n",
    "\n",
    "# Encode diagnosis codes: 1 if present, 0 if null\n",
    "for col in diagnosis_cols:\n",
    "    inpatient[col + '_present'] = inpatient[col].notna().astype(int)\n",
    "\n",
    "# Encode procedure codes: 1 if present, 0 if null\n",
    "for col in procedure_cols:\n",
    "    inpatient[col + '_present'] = inpatient[col].notna().astype(int)\n",
    "\n",
    "# Optional: compute total diagnoses and total procedures per claim\n",
    "inpatient['num_diagnoses'] = inpatient[[col + '_present' for col in diagnosis_cols]].sum(axis=1)\n",
    "inpatient['num_procedures'] = inpatient[[col + '_present' for col in procedure_cols]].sum(axis=1)\n",
    "\n",
    "# Quick check\n",
    "inpatient[['num_diagnoses','num_procedures'] + [col + '_present' for col in diagnosis_cols[:3]] + [col + '_present' for col in procedure_cols[:3]]].head()\n",
    "\n",
    "\n",
    "\n",
    "#test:\n",
    "\n",
    "\n",
    "# List of diagnosis and procedure columns\n",
    "diagnosis_cols = [f'ClmDiagnosisCode_{i}' for i in range(1, 10)]\n",
    "procedure_cols = [f'ClmProcedureCode_{i}' for i in range(1, 6)]\n",
    "\n",
    "# Encode diagnosis codes: 1 if present, 0 if null\n",
    "for col in diagnosis_cols:\n",
    "    inpatient_test[col + '_present'] = inpatient_test[col].notna().astype(int)\n",
    "\n",
    "# Encode procedure codes: 1 if present, 0 if null\n",
    "for col in procedure_cols:\n",
    "    inpatient_test[col + '_present'] = inpatient_test[col].notna().astype(int)\n",
    "\n",
    "# Optional: compute total diagnoses and total procedures per claim\n",
    "inpatient_test['num_diagnoses'] = inpatient_test[[col + '_present' for col in diagnosis_cols]].sum(axis=1)\n",
    "inpatient_test['num_procedures'] = inpatient_test[[col + '_present' for col in procedure_cols]].sum(axis=1)\n",
    "\n",
    "# Quick check\n",
    "inpatient_test[['num_diagnoses','num_procedures'] + [col + '_present' for col in diagnosis_cols[:3]] + [col + '_present' for col in procedure_cols[:3]]].head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a513bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915cfb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "today = pd.Timestamp.today()\n",
    "\n",
    "# safe helpers (fill missing numeric amounts to 0)\n",
    "inpatient['DeductibleAmtPaid'] = inpatient['DeductibleAmtPaid'].fillna(0)\n",
    "inpatient['InscClaimAmtReimbursed'] = inpatient['InscClaimAmtReimbursed'].fillna(0)\n",
    "\n",
    "# Payment flags\n",
    "inpatient['patient_paid'] = (inpatient['DeductibleAmtPaid'] > 0).astype(int)\n",
    "inpatient['insurer_paid'] = (inpatient['InscClaimAmtReimbursed'] > 0).astype(int)\n",
    "inpatient['any_payment'] = ((inpatient['patient_paid'] == 1) | (inpatient['insurer_paid'] == 1)).astype(int)\n",
    "\n",
    "# Duration features (in days). Use NaN-safe computations.\n",
    "inpatient['los_days'] = (inpatient['DischargeDt'] - inpatient['AdmissionDt']).dt.days\n",
    "inpatient['claim_length_days'] = (inpatient['ClaimEndDt'] - inpatient['ClaimStartDt']).dt.days\n",
    "\n",
    "# Avoid negative/infinite weirdness: keep NaNs where dates missing\n",
    "# Basic anomaly flags (strong anomalies)\n",
    "inpatient['ClaimStart_after_ClaimEnd'] = ((inpatient['ClaimStartDt'].notna() & inpatient['ClaimEndDt'].notna()) &\n",
    "                                         (inpatient['ClaimStartDt'] > inpatient['ClaimEndDt'])).astype(int)\n",
    "\n",
    "inpatient['Admission_after_Discharge'] = ((inpatient['AdmissionDt'].notna() & inpatient['DischargeDt'].notna()) &\n",
    "                                          (inpatient['AdmissionDt'] > inpatient['DischargeDt'])).astype(int)\n",
    "\n",
    "inpatient['Future_dates'] = (inpatient[['ClaimStartDt','ClaimEndDt','AdmissionDt','DischargeDt']].gt(today)\n",
    "                             .any(axis=1)).astype(int)\n",
    "\n",
    "# Potential anomalies (sometimes legitimate)\n",
    "inpatient['ClaimStart_before_Admission'] = ((inpatient['ClaimStartDt'].notna() & inpatient['AdmissionDt'].notna()) &\n",
    "                                           (inpatient['ClaimStartDt'] < inpatient['AdmissionDt'])).astype(int)\n",
    "\n",
    "inpatient['ClaimEnd_after_Discharge'] = ((inpatient['ClaimEndDt'].notna() & inpatient['DischargeDt'].notna()) &\n",
    "                                         (inpatient['ClaimEndDt'] > inpatient['DischargeDt'])).astype(int)\n",
    "\n",
    "# Conditional anomaly features using payment info:\n",
    "# - If claim extends after discharge AND no patient payment, mark more suspicious\n",
    "inpatient['ClaimEnd_after_Discharge_no_patient_payment'] = (\n",
    "    (inpatient['ClaimEnd_after_Discharge'] == 1) & (inpatient['patient_paid'] == 0)\n",
    ").astype(int)\n",
    "\n",
    "# - If claim starts before admission AND there's no payment (insurer nor patient), mark suspicious\n",
    "inpatient['ClaimStart_before_Admission_no_payment'] = (\n",
    "    (inpatient['ClaimStart_before_Admission'] == 1) & (inpatient['any_payment'] == 0)\n",
    ").astype(int)\n",
    "\n",
    "# Length-based anomalies:\n",
    "# - If claim duration is much larger than LOS (e.g., claim_length > 2 * los_days), suspicious.\n",
    "#   Requires both claim_length and los_days to be non-null and los_days >= 0.\n",
    "inpatient['claim_length_vs_los_ratio'] = None\n",
    "mask_valid_lengths = inpatient['claim_length_days'].notna() & inpatient['los_days'].notna() & (inpatient['los_days'] >= 0)\n",
    "inpatient.loc[mask_valid_lengths, 'claim_length_vs_los_ratio'] = (\n",
    "    inpatient.loc[mask_valid_lengths, 'claim_length_days'] / inpatient.loc[mask_valid_lengths, 'los_days'].replace({0: 1})\n",
    ")\n",
    "inpatient['claim_length_vs_los_ratio'] = inpatient['claim_length_vs_los_ratio'].astype(float)\n",
    "\n",
    "# Flag when ratio is large (use >2 as an initial heuristic)\n",
    "inpatient['claim_length_much_greater_than_los'] = ((inpatient['claim_length_vs_los_ratio'] > 2) & mask_valid_lengths).astype(int)\n",
    "\n",
    "# Build a weighted date-anomaly score:\n",
    "# weight strong anomalies higher (3), conditional suspicious (2), potential anomalies (1)\n",
    "inpatient['date_anomaly_score'] = (\n",
    "      3 * inpatient['ClaimStart_after_ClaimEnd'].fillna(0)\n",
    "    + 3 * inpatient['Admission_after_Discharge'].fillna(0)\n",
    "    + 3 * inpatient['Future_dates'].fillna(0)\n",
    "    + 2 * inpatient['ClaimEnd_after_Discharge_no_patient_payment'].fillna(0)\n",
    "    + 1 * inpatient['ClaimStart_before_Admission_no_payment'].fillna(0)\n",
    "    + 2 * inpatient['claim_length_much_greater_than_los'].fillna(0)\n",
    ")\n",
    "\n",
    "# For transparency, also keep a simple count of distinct date issues (unweighted)\n",
    "date_issue_cols = ['ClaimStart_after_ClaimEnd','Admission_after_Discharge','Future_dates',\n",
    "                   'ClaimEnd_after_Discharge','ClaimStart_before_Admission']\n",
    "inpatient['date_issue_count'] = inpatient[date_issue_cols].sum(axis=1)\n",
    "\n",
    "# Quick summary for review\n",
    "summary = inpatient[['ClaimStart_after_ClaimEnd','Admission_after_Discharge','ClaimStart_before_Admission',\n",
    "                     'ClaimEnd_after_Discharge','ClaimEnd_after_Discharge_no_patient_payment',\n",
    "                     'ClaimStart_before_Admission_no_payment','Future_dates',\n",
    "                     'claim_length_much_greater_than_los','date_anomaly_score','date_issue_count']].sum()\n",
    "print(\"Feature summary (counts / sums):\")\n",
    "print(summary)\n",
    "\n",
    "# Example: show top suspicious rows by score\n",
    "print(\"\\nTop suspicious claims by date_anomaly_score:\")\n",
    "print(inpatient.sort_values('date_anomaly_score', ascending=False)\n",
    "                .loc[:, ['ClaimID','Provider','BeneID','date_anomaly_score','date_issue_count',\n",
    "                         'ClaimStartDt','ClaimEndDt','AdmissionDt','DischargeDt',\n",
    "                         'patient_paid','insurer_paid','InscClaimAmtReimbursed','DeductibleAmtPaid']]\n",
    "                .head(20))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#test:\n",
    "\n",
    "\n",
    "\n",
    "today = pd.Timestamp.today()\n",
    "\n",
    "# safe helpers (fill missing numeric amounts to 0)\n",
    "inpatient_test['DeductibleAmtPaid'] = inpatient_test['DeductibleAmtPaid'].fillna(0)\n",
    "inpatient_test['InscClaimAmtReimbursed'] = inpatient_test['InscClaimAmtReimbursed'].fillna(0)\n",
    "\n",
    "# Payment flags\n",
    "inpatient_test['patient_paid'] = (inpatient_test['DeductibleAmtPaid'] > 0).astype(int)\n",
    "inpatient_test['insurer_paid'] = (inpatient_test['InscClaimAmtReimbursed'] > 0).astype(int)\n",
    "inpatient_test['any_payment'] = ((inpatient_test['patient_paid'] == 1) | (inpatient_test['insurer_paid'] == 1)).astype(int)\n",
    "\n",
    "# Duration features (in days). Use NaN-safe computations.\n",
    "inpatient_test['los_days'] = (inpatient_test['DischargeDt'] - inpatient_test['AdmissionDt']).dt.days\n",
    "inpatient_test['claim_length_days'] = (inpatient_test['ClaimEndDt'] - inpatient_test['ClaimStartDt']).dt.days\n",
    "\n",
    "# Avoid negative/infinite weirdness: keep NaNs where dates missing\n",
    "# Basic anomaly flags (strong anomalies)\n",
    "inpatient_test['ClaimStart_after_ClaimEnd'] = ((inpatient_test['ClaimStartDt'].notna() & inpatient_test['ClaimEndDt'].notna()) &\n",
    "                                         (inpatient_test['ClaimStartDt'] > inpatient_test['ClaimEndDt'])).astype(int)\n",
    "\n",
    "inpatient_test['Admission_after_Discharge'] = ((inpatient_test['AdmissionDt'].notna() & inpatient_test['DischargeDt'].notna()) &\n",
    "                                          (inpatient_test['AdmissionDt'] > inpatient_test['DischargeDt'])).astype(int)\n",
    "\n",
    "inpatient_test['Future_dates'] = (inpatient_test[['ClaimStartDt','ClaimEndDt','AdmissionDt','DischargeDt']].gt(today)\n",
    "                             .any(axis=1)).astype(int)\n",
    "\n",
    "# Potential anomalies (sometimes legitimate)\n",
    "inpatient_test['ClaimStart_before_Admission'] = ((inpatient_test['ClaimStartDt'].notna() & inpatient_test['AdmissionDt'].notna()) &\n",
    "                                           (inpatient_test['ClaimStartDt'] < inpatient_test['AdmissionDt'])).astype(int)\n",
    "\n",
    "inpatient_test['ClaimEnd_after_Discharge'] = ((inpatient_test['ClaimEndDt'].notna() & inpatient_test['DischargeDt'].notna()) &\n",
    "                                         (inpatient_test['ClaimEndDt'] > inpatient_test['DischargeDt'])).astype(int)\n",
    "\n",
    "# Conditional anomaly features using payment info:\n",
    "# - If claim extends after discharge AND no patient payment, mark more suspicious\n",
    "inpatient_test['ClaimEnd_after_Discharge_no_patient_payment'] = (\n",
    "    (inpatient_test['ClaimEnd_after_Discharge'] == 1) & (inpatient_test['patient_paid'] == 0)\n",
    ").astype(int)\n",
    "\n",
    "# - If claim starts before admission AND there's no payment (insurer nor patient), mark suspicious\n",
    "inpatient_test['ClaimStart_before_Admission_no_payment'] = (\n",
    "    (inpatient_test['ClaimStart_before_Admission'] == 1) & (inpatient_test['any_payment'] == 0)\n",
    ").astype(int)\n",
    "\n",
    "# Length-based anomalies:\n",
    "# - If claim duration is much larger than LOS (e.g., claim_length > 2 * los_days), suspicious.\n",
    "#   Requires both claim_length and los_days to be non-null and los_days >= 0.\n",
    "inpatient_test['claim_length_vs_los_ratio'] = None\n",
    "mask_valid_lengths = inpatient_test['claim_length_days'].notna() & inpatient_test['los_days'].notna() & (inpatient_test['los_days'] >= 0)\n",
    "inpatient_test.loc[mask_valid_lengths, 'claim_length_vs_los_ratio'] = (\n",
    "    inpatient_test.loc[mask_valid_lengths, 'claim_length_days'] / inpatient_test.loc[mask_valid_lengths, 'los_days'].replace({0: 1})\n",
    ")\n",
    "inpatient_test['claim_length_vs_los_ratio'] = inpatient_test['claim_length_vs_los_ratio'].astype(float)\n",
    "\n",
    "# Flag when ratio is large (use >2 as an initial heuristic)\n",
    "inpatient_test['claim_length_much_greater_than_los'] = ((inpatient_test['claim_length_vs_los_ratio'] > 2) & mask_valid_lengths).astype(int)\n",
    "\n",
    "# Build a weighted date-anomaly score:\n",
    "# weight strong anomalies higher (3), conditional suspicious (2), potential anomalies (1)\n",
    "inpatient_test['date_anomaly_score'] = (\n",
    "      3 * inpatient_test['ClaimStart_after_ClaimEnd'].fillna(0)\n",
    "    + 3 * inpatient_test['Admission_after_Discharge'].fillna(0)\n",
    "    + 3 * inpatient_test['Future_dates'].fillna(0)\n",
    "    + 2 * inpatient_test['ClaimEnd_after_Discharge_no_patient_payment'].fillna(0)\n",
    "    + 1 * inpatient_test['ClaimStart_before_Admission_no_payment'].fillna(0)\n",
    "    + 2 * inpatient_test['claim_length_much_greater_than_los'].fillna(0)\n",
    ")\n",
    "\n",
    "# For transparency, also keep a simple count of distinct date issues (unweighted)\n",
    "date_issue_cols = ['ClaimStart_after_ClaimEnd','Admission_after_Discharge','Future_dates',\n",
    "                   'ClaimEnd_after_Discharge','ClaimStart_before_Admission']\n",
    "inpatient_test['date_issue_count'] = inpatient_test[date_issue_cols].sum(axis=1)\n",
    "\n",
    "# Quick summary for review\n",
    "summary = inpatient_test[['ClaimStart_after_ClaimEnd','Admission_after_Discharge','ClaimStart_before_Admission',\n",
    "                     'ClaimEnd_after_Discharge','ClaimEnd_after_Discharge_no_patient_payment',\n",
    "                     'ClaimStart_before_Admission_no_payment','Future_dates',\n",
    "                     'claim_length_much_greater_than_los','date_anomaly_score','date_issue_count']].sum()\n",
    "print(\"Feature summary (counts / sums):\")\n",
    "print(summary)\n",
    "\n",
    "# Example: show top suspicious rows by score\n",
    "print(\"\\nTop suspicious claims by date_anomaly_score:\")\n",
    "print(inpatient_test.sort_values('date_anomaly_score', ascending=False)\n",
    "                .loc[:, ['ClaimID','Provider','BeneID','date_anomaly_score','date_issue_count',\n",
    "                         'ClaimStartDt','ClaimEndDt','AdmissionDt','DischargeDt',\n",
    "                         'patient_paid','insurer_paid','InscClaimAmtReimbursed','DeductibleAmtPaid']]\n",
    "                .head(20))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc02f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each feature (column), calculate % of missing values\n",
    "for col in inpatient.columns:\n",
    "    missing_pct = inpatient[col].isnull().sum() / len(inpatient) * 100\n",
    "    print(f\"{col}: {missing_pct:.2f}% missing\")\n",
    "\n",
    "#test:\n",
    "\n",
    "for col in inpatient_test.columns:\n",
    "    missing_pct = inpatient_test[col].isnull().sum() / len(inpatient_test) * 100\n",
    "    print(f\"{col}: {missing_pct:.2f}% missing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2555778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inpatient\n",
    "#1. encode physcians as either 1(present) or 0(absent) for each claim\n",
    "#2. count frequency of appearance of each physcians\n",
    "#3. sum number of physcians per person \n",
    "\n",
    "\n",
    "# Columns for physicians\n",
    "phys_cols = ['AttendingPhysician', 'OperatingPhysician', 'OtherPhysician']\n",
    "\n",
    "# 1️ Frequency Encoding\n",
    "\n",
    "# Count how many times each physician ID appears across all three columns\n",
    "phys_freq = pd.concat([inpatient[col] for col in phys_cols]).value_counts()\n",
    "\n",
    "# Map the frequency back to each physician column, missing IDs get 0\n",
    "for col in phys_cols:\n",
    "    inpatient[col + '_freq'] = inpatient[col].map(phys_freq).fillna(0)\n",
    "\n",
    "\n",
    "#2. 0/1 Presence Encoding\n",
    "# Create new columns indicating presence of a physician ID\n",
    "for col in phys_cols:\n",
    "    inpatient[col + '_presence'] = inpatient[col].notna().astype(int)\n",
    "\n",
    "\n",
    "# 3 Number of Physicians per claim\n",
    "\n",
    "# Sum the presence columns to get total number of physicians per claim\n",
    "inpatient['num_physicians'] = inpatient[[col + '_presence' for col in phys_cols]].sum(axis=1)\n",
    "\n",
    "\n",
    "print(inpatient[[col + '_freq' for col in phys_cols] +\n",
    "               [col + '_presence' for col in phys_cols] +\n",
    "               ['num_physicians']].head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#test:\n",
    "\n",
    "\n",
    "#inpatient\n",
    "#1. encode physcians as either 1(present) or 0(absent) for each claim\n",
    "#2. count frequency of appearance of each physcians\n",
    "#3. sum number of physcians per person \n",
    "\n",
    "\n",
    "# Columns for physicians\n",
    "phys_cols = ['AttendingPhysician', 'OperatingPhysician', 'OtherPhysician']\n",
    "\n",
    "# 1️ Frequency Encoding\n",
    "\n",
    "# Count how many times each physician ID appears across all three columns\n",
    "phys_freq = pd.concat([inpatient_test[col] for col in phys_cols]).value_counts()\n",
    "\n",
    "# Map the frequency back to each physician column, missing IDs get 0\n",
    "for col in phys_cols:\n",
    "    inpatient_test[col + '_freq'] = inpatient_test[col].map(phys_freq).fillna(0)\n",
    "\n",
    "\n",
    "#2. 0/1 Presence Encoding\n",
    "# Create new columns indicating presence of a physician ID\n",
    "for col in phys_cols:\n",
    "    inpatient_test[col + '_presence'] = inpatient_test[col].notna().astype(int)\n",
    "\n",
    "\n",
    "# 3 Number of Physicians per claim\n",
    "\n",
    "# Sum the presence columns to get total number of physicians per claim\n",
    "inpatient_test['num_physicians'] = inpatient_test[[col + '_presence' for col in phys_cols]].sum(axis=1)\n",
    "\n",
    "\n",
    "print(inpatient_test[[col + '_freq' for col in phys_cols] +\n",
    "               [col + '_presence' for col in phys_cols] +\n",
    "               ['num_physicians']].head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65806b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diagnosis columns\n",
    "diag_cols = [f'ClmDiagnosisCode_{i}' for i in range(1, 11)]\n",
    "\n",
    "# 0. Ensure numeric payments and claim_length_days exist\n",
    "inpatient['DeductibleAmtPaid'] = inpatient['DeductibleAmtPaid'].fillna(0)\n",
    "inpatient['InscClaimAmtReimbursed'] = inpatient['InscClaimAmtReimbursed'].fillna(0)\n",
    "inpatient['total_payment'] = inpatient['DeductibleAmtPaid'] + inpatient['InscClaimAmtReimbursed']\n",
    "\n",
    "# ensure claim_length_days exists and use at least 1 day to avoid div by 0\n",
    "if 'claim_length_days' not in inpatient.columns:\n",
    "    inpatient['claim_length_days'] = (inpatient['ClaimEndDt'] - inpatient['ClaimStartDt']).dt.days\n",
    "inpatient['claim_length_days'] = inpatient['claim_length_days'].fillna(0).astype(float)\n",
    "inpatient['claim_length_days_nonzero'] = inpatient['claim_length_days'].apply(lambda x: x if x >= 1 else 1.0)\n",
    "\n",
    "# 1. payment per day (ppd) for each claim\n",
    "inpatient['claim_payment_ppd'] = inpatient['total_payment'] / inpatient['claim_length_days_nonzero']\n",
    "\n",
    "# 2. build long table of (ClaimID, diag_code, claim_payment_ppd)\n",
    "# keep only valid diagnosis codes (non-null and not placeholder like 'Unknown' or '')\n",
    "long = (inpatient[['ClaimID'] + diag_cols + ['claim_payment_ppd']]\n",
    "        .set_index('ClaimID')\n",
    "        .reset_index())\n",
    "\n",
    "# melt\n",
    "melted = long.melt(id_vars=['ClaimID','claim_payment_ppd'], value_vars=diag_cols,\n",
    "                   var_name='diag_slot', value_name='diag_code')\n",
    "\n",
    "# clean diag_code: drop NaN and empty/Unknown placeholders\n",
    "melted['diag_code'] = melted['diag_code'].astype(str).str.strip()\n",
    "# treat common placeholders as missing\n",
    "placeholders = {'nan', 'none', 'unknown', 'na', 'nan.', ''} \n",
    "melted = melted[~melted['diag_code'].str.lower().isin(placeholders)]\n",
    "melted = melted[~melted['diag_code'].isin(['nan', 'None'])]\n",
    "\n",
    "# 3. compute diag-level stats: count, mean_ppd, median_ppd\n",
    "diag_stats = (melted.groupby('diag_code')['claim_payment_ppd']\n",
    "                    .agg(['count', 'mean', 'median'])\n",
    "                    .rename(columns={'mean':'mean_ppd', 'median':'median_ppd'})\n",
    "                    .reset_index())\n",
    "\n",
    "# 4. smoothing (shrink mean toward global mean) to stabilize rare codes\n",
    "global_mean = melted['claim_payment_ppd'].median()  # median as robust global center\n",
    "k = 10.0  # prior strength (tuneable)\n",
    "diag_stats['smoothed_mean_ppd'] = (diag_stats['count'] * diag_stats['mean_ppd'] + k * global_mean) / (diag_stats['count'] + k)\n",
    "\n",
    "# 5. map stats back to each diag slot in inpatient\n",
    "# build mapping dicts\n",
    "smoothed_map = diag_stats.set_index('diag_code')['smoothed_mean_ppd'].to_dict()\n",
    "median_map = diag_stats.set_index('diag_code')['median_ppd'].to_dict()\n",
    "count_map = diag_stats.set_index('diag_code')['count'].to_dict()\n",
    "\n",
    "# For each diag slot, create mapped expected_ppd, median_ppd, count\n",
    "for col in diag_cols:\n",
    "    inpatient[col + '_diag_exp_ppd'] = inpatient[col].map(smoothed_map).fillna(0.0)\n",
    "    inpatient[col + '_diag_median_ppd'] = inpatient[col].map(median_map).fillna(0.0)\n",
    "    inpatient[col + '_diag_count'] = inpatient[col].map(count_map).fillna(0).astype(int)\n",
    "\n",
    "# 6. compute claim-level aggregated diagnosis expectations\n",
    "# consider only diag slots with nonzero expected (i.e., present in mapping)\n",
    "exp_cols = [c + '_diag_exp_ppd' for c in diag_cols]\n",
    "med_cols = [c + '_diag_median_ppd' for c in diag_cols]\n",
    "cnt_cols = [c + '_diag_count' for c in diag_cols]\n",
    "\n",
    "# mean expected ppd across present diagnosis codes (ignore zeros)\n",
    "inpatient['diag_expected_mean_ppd'] = inpatient[exp_cols].replace(0, np.nan).mean(axis=1).fillna(0.0)\n",
    "inpatient['diag_expected_median_ppd'] = inpatient[med_cols].replace(0, np.nan).median(axis=1).fillna(0.0)\n",
    "inpatient['diag_expected_max_ppd'] = inpatient[exp_cols].max(axis=1).fillna(0.0)\n",
    "inpatient['diag_expected_sum_ppd'] = inpatient[exp_cols].sum(axis=1).fillna(0.0)\n",
    "inpatient['diag_present_count'] = (inpatient[exp_cols] > 0).sum(axis=1)\n",
    "\n",
    "# 7. ratio features: actual claim_ppd divided by expected\n",
    "# if expected mean is 0 (no known diag), set ratio to NaN (or large sentinel); here use NaN\n",
    "inpatient['claim_ppd_to_diag_expected_mean'] = np.where(\n",
    "    inpatient['diag_expected_mean_ppd'] > 0,\n",
    "    inpatient['claim_payment_ppd'] / inpatient['diag_expected_mean_ppd'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "inpatient['claim_ppd_to_diag_expected_max'] = np.where(\n",
    "    inpatient['diag_expected_max_ppd'] > 0,\n",
    "    inpatient['claim_payment_ppd'] / inpatient['diag_expected_max_ppd'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# 8. rare-diagnosis flags: any diag in claim has count < threshold\n",
    "rare_threshold = 5\n",
    "inpatient['claim_has_rare_diag'] = (inpatient[cnt_cols] > 0).apply(lambda row: any(row < rare_threshold), axis=1).astype(int)\n",
    "\n",
    "# 9. diagnostic expected vs actual gap (absolute and percent)\n",
    "inpatient['diag_expected_sum_ppd'] = inpatient['diag_expected_sum_ppd'].replace(0, np.nan)\n",
    "inpatient['expected_vs_actual_gap_ppd'] = inpatient['claim_payment_ppd'] - inpatient['diag_expected_mean_ppd']  # absolute gap\n",
    "inpatient['expected_vs_actual_pct_ppd'] = inpatient['claim_payment_ppd'] / inpatient['diag_expected_mean_ppd'].replace({0: np.nan})\n",
    "\n",
    "# 10. clean up temporary columns if desired (optional)\n",
    "# keep final features: diag_expected_mean_ppd, diag_expected_median_ppd, diag_expected_max_ppd,\n",
    "# diag_expected_sum_ppd, diag_present_count, claim_ppd_to_diag_expected_mean, claim_has_rare_diag, expected_vs_actual_gap_ppd\n",
    "final_diag_features = [\n",
    "    'diag_expected_mean_ppd', 'diag_expected_median_ppd', 'diag_expected_max_ppd',\n",
    "    'diag_expected_sum_ppd', 'diag_present_count', 'claim_ppd_to_diag_expected_mean',\n",
    "    'claim_ppd_to_diag_expected_max', 'claim_has_rare_diag', 'expected_vs_actual_gap_ppd',\n",
    "    'expected_vs_actual_pct_ppd'\n",
    "]\n",
    "\n",
    "# (optional) print a quick summary\n",
    "print(\"Diagnosis-payment feature creation complete.\")\n",
    "print(\"Number of unique diagnosis codes modeled:\", len(diag_stats))\n",
    "print(diag_stats[['diag_code','count','median_ppd','smoothed_mean_ppd']].sort_values('count', ascending=False).head(10))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#test:\n",
    "\n",
    "\n",
    "# diagnosis columns\n",
    "diag_cols = [f'ClmDiagnosisCode_{i}' for i in range(1, 11)]\n",
    "\n",
    "# 0. Ensure numeric payments and claim_length_days exist\n",
    "inpatient_test['DeductibleAmtPaid'] = inpatient_test['DeductibleAmtPaid'].fillna(0)\n",
    "inpatient_test['InscClaimAmtReimbursed'] = inpatient_test['InscClaimAmtReimbursed'].fillna(0)\n",
    "inpatient_test['total_payment'] = inpatient_test['DeductibleAmtPaid'] + inpatient_test['InscClaimAmtReimbursed']\n",
    "\n",
    "# ensure claim_length_days exists and use at least 1 day to avoid div by 0\n",
    "if 'claim_length_days' not in inpatient_test.columns:\n",
    "    inpatient_test['claim_length_days'] = (inpatient_test['ClaimEndDt'] - inpatient_test['ClaimStartDt']).dt.days\n",
    "inpatient_test['claim_length_days'] = inpatient_test['claim_length_days'].fillna(0).astype(float)\n",
    "inpatient_test['claim_length_days_nonzero'] = inpatient_test['claim_length_days'].apply(lambda x: x if x >= 1 else 1.0)\n",
    "\n",
    "# 1. payment per day (ppd) for each claim\n",
    "inpatient_test['claim_payment_ppd'] = inpatient_test['total_payment'] / inpatient_test['claim_length_days_nonzero']\n",
    "\n",
    "# 2. build long table of (ClaimID, diag_code, claim_payment_ppd)\n",
    "# keep only valid diagnosis codes (non-null and not placeholder like 'Unknown' or '')\n",
    "long = (inpatient_test[['ClaimID'] + diag_cols + ['claim_payment_ppd']]\n",
    "        .set_index('ClaimID')\n",
    "        .reset_index())\n",
    "\n",
    "# melt\n",
    "melted = long.melt(id_vars=['ClaimID','claim_payment_ppd'], value_vars=diag_cols,\n",
    "                   var_name='diag_slot', value_name='diag_code')\n",
    "\n",
    "# clean diag_code: drop NaN and empty/Unknown placeholders\n",
    "melted['diag_code'] = melted['diag_code'].astype(str).str.strip()\n",
    "# treat common placeholders as missing\n",
    "placeholders = {'nan', 'none', 'unknown', 'na', 'nan.', ''} \n",
    "melted = melted[~melted['diag_code'].str.lower().isin(placeholders)]\n",
    "melted = melted[~melted['diag_code'].isin(['nan', 'None'])]\n",
    "\n",
    "# 3. compute diag-level stats: count, mean_ppd, median_ppd\n",
    "diag_stats = (melted.groupby('diag_code')['claim_payment_ppd']\n",
    "                    .agg(['count', 'mean', 'median'])\n",
    "                    .rename(columns={'mean':'mean_ppd', 'median':'median_ppd'})\n",
    "                    .reset_index())\n",
    "\n",
    "# 4. smoothing (shrink mean toward global mean) to stabilize rare codes\n",
    "global_mean = melted['claim_payment_ppd'].median()  # median as robust global center\n",
    "k = 10.0  # prior strength (tuneable)\n",
    "diag_stats['smoothed_mean_ppd'] = (diag_stats['count'] * diag_stats['mean_ppd'] + k * global_mean) / (diag_stats['count'] + k)\n",
    "\n",
    "# 5. map stats back to each diag slot in inpatient_test\n",
    "# build mapping dicts\n",
    "smoothed_map = diag_stats.set_index('diag_code')['smoothed_mean_ppd'].to_dict()\n",
    "median_map = diag_stats.set_index('diag_code')['median_ppd'].to_dict()\n",
    "count_map = diag_stats.set_index('diag_code')['count'].to_dict()\n",
    "\n",
    "# For each diag slot, create mapped expected_ppd, median_ppd, count\n",
    "for col in diag_cols:\n",
    "    inpatient_test[col + '_diag_exp_ppd'] = inpatient_test[col].map(smoothed_map).fillna(0.0)\n",
    "    inpatient_test[col + '_diag_median_ppd'] = inpatient_test[col].map(median_map).fillna(0.0)\n",
    "    inpatient_test[col + '_diag_count'] = inpatient_test[col].map(count_map).fillna(0).astype(int)\n",
    "\n",
    "# 6. compute claim-level aggregated diagnosis expectations\n",
    "# consider only diag slots with nonzero expected (i.e., present in mapping)\n",
    "exp_cols = [c + '_diag_exp_ppd' for c in diag_cols]\n",
    "med_cols = [c + '_diag_median_ppd' for c in diag_cols]\n",
    "cnt_cols = [c + '_diag_count' for c in diag_cols]\n",
    "\n",
    "# mean expected ppd across present diagnosis codes (ignore zeros)\n",
    "inpatient_test['diag_expected_mean_ppd'] = inpatient_test[exp_cols].replace(0, np.nan).mean(axis=1).fillna(0.0)\n",
    "inpatient_test['diag_expected_median_ppd'] = inpatient_test[med_cols].replace(0, np.nan).median(axis=1).fillna(0.0)\n",
    "inpatient_test['diag_expected_max_ppd'] = inpatient_test[exp_cols].max(axis=1).fillna(0.0)\n",
    "inpatient_test['diag_expected_sum_ppd'] = inpatient_test[exp_cols].sum(axis=1).fillna(0.0)\n",
    "inpatient_test['diag_present_count'] = (inpatient_test[exp_cols] > 0).sum(axis=1)\n",
    "\n",
    "# 7. ratio features: actual claim_ppd divided by expected\n",
    "# if expected mean is 0 (no known diag), set ratio to NaN (or large sentinel); here use NaN\n",
    "inpatient_test['claim_ppd_to_diag_expected_mean'] = np.where(\n",
    "    inpatient_test['diag_expected_mean_ppd'] > 0,\n",
    "    inpatient_test['claim_payment_ppd'] / inpatient_test['diag_expected_mean_ppd'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "inpatient_test['claim_ppd_to_diag_expected_max'] = np.where(\n",
    "    inpatient_test['diag_expected_max_ppd'] > 0,\n",
    "    inpatient_test['claim_payment_ppd'] / inpatient_test['diag_expected_max_ppd'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# 8. rare-diagnosis flags: any diag in claim has count < threshold\n",
    "rare_threshold = 5\n",
    "inpatient_test['claim_has_rare_diag'] = (inpatient_test[cnt_cols] > 0).apply(lambda row: any(row < rare_threshold), axis=1).astype(int)\n",
    "\n",
    "# 9. diagnostic expected vs actual gap (absolute and percent)\n",
    "inpatient_test['diag_expected_sum_ppd'] = inpatient_test['diag_expected_sum_ppd'].replace(0, np.nan)\n",
    "inpatient_test['expected_vs_actual_gap_ppd'] = inpatient_test['claim_payment_ppd'] - inpatient_test['diag_expected_mean_ppd']  # absolute gap\n",
    "inpatient_test['expected_vs_actual_pct_ppd'] = inpatient_test['claim_payment_ppd'] / inpatient_test['diag_expected_mean_ppd'].replace({0: np.nan})\n",
    "\n",
    "# 10. clean up temporary columns if desired (optional)\n",
    "final_diag_features = [\n",
    "    'diag_expected_mean_ppd', 'diag_expected_median_ppd', 'diag_expected_max_ppd',\n",
    "    'diag_expected_sum_ppd', 'diag_present_count', 'claim_ppd_to_diag_expected_mean',\n",
    "    'claim_ppd_to_diag_expected_max', 'claim_has_rare_diag', 'expected_vs_actual_gap_ppd',\n",
    "    'expected_vs_actual_pct_ppd'\n",
    "]\n",
    "\n",
    "# (optional) print a quick summary\n",
    "print(\"Diagnosis-payment feature creation complete.\")\n",
    "print(\"Number of unique diagnosis codes modeled:\", len(diag_stats))\n",
    "print(diag_stats[['diag_code','count','median_ppd','smoothed_mean_ppd']].sort_values('count', ascending=False).head(10))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b99a828",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpatient.head(5)\n",
    "#what is next: handle outliers(top), encoding for provider and Physicians, check if there are any NAN left\n",
    "#read about: Optional: Feature transformations, Log-transform payments, ratios to reduce skew, Scaling numeric features if using linear models\n",
    "#Temporal / rolling features, Trend of payments or anomalies over time per provider\n",
    "#Save preprocessing artifacts Mapping dictionaries for diag/payment, provider freq, scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0453cb73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6fdcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###outpatient\n",
    "#1) Parse date columns (safe)\n",
    "date_cols = outpatient.columns[outpatient.columns.str.contains('Dt|Date', case=False)]\n",
    "for col in date_cols:\n",
    "    outpatient[col] = pd.to_datetime(outpatient[col], errors='coerce')\n",
    "\n",
    "today = pd.Timestamp.today()\n",
    "\n",
    "# 2) Diagnosis / Procedure presence flags & counts\n",
    "diag_cols = [f'ClmDiagnosisCode_{i}' for i in range(1, 11)]\n",
    "procedure_cols = [f'ClmProcedureCode_{i}' for i in range(1, 7)]\n",
    "\n",
    "# presence flags (1 if present, 0 if null/empty/placeholder)\n",
    "placeholders = {'nan', 'none', 'unknown', 'na', '', 'nan.'}\n",
    "for col in diag_cols:\n",
    "    outpatient[col] = outpatient[col].astype(str).str.strip().replace({c: np.nan for c in placeholders})\n",
    "    outpatient[col + '_present'] = outpatient[col].notna().astype(int)\n",
    "\n",
    "for col in procedure_cols:\n",
    "    outpatient[col] = outpatient[col].astype(str).str.strip().replace({c: np.nan for c in placeholders})\n",
    "    outpatient[col + '_present'] = outpatient[col].notna().astype(int)\n",
    "\n",
    "# totals per claim\n",
    "outpatient['num_diagnoses'] = outpatient[[c + '_present' for c in diag_cols]].sum(axis=1)\n",
    "outpatient['num_procedures'] = outpatient[[c + '_present' for c in procedure_cols]].sum(axis=1)\n",
    "\n",
    "# 3) Safe numeric payments\n",
    "outpatient['DeductibleAmtPaid'] = outpatient['DeductibleAmtPaid'].fillna(0).astype(float)\n",
    "outpatient['InscClaimAmtReimbursed'] = outpatient['InscClaimAmtReimbursed'].fillna(0).astype(float)\n",
    "outpatient['total_payment'] = outpatient['DeductibleAmtPaid'] + outpatient['InscClaimAmtReimbursed']\n",
    "\n",
    "# payment flags\n",
    "outpatient['patient_paid'] = (outpatient['DeductibleAmtPaid'] > 0).astype(int)\n",
    "outpatient['insurer_paid'] = (outpatient['InscClaimAmtReimbursed'] > 0).astype(int)\n",
    "outpatient['any_payment'] = ((outpatient['patient_paid'] == 1) | (outpatient['insurer_paid'] == 1)).astype(int)\n",
    "\n",
    "# 4) Duration feature (days) — usually 0 for outpatient but keep it\n",
    "outpatient['claim_duration_days'] = (outpatient['ClaimEndDt'] - outpatient['ClaimStartDt']).dt.days\n",
    "# keep NaNs if dates missing; also a nonzero-safe version for division when needed\n",
    "outpatient['claim_duration_days_nonzero'] = outpatient['claim_duration_days'].apply(lambda x: x if (pd.notna(x) and x >= 1) else 1.0)\n",
    "\n",
    "# 5) Date anomalies relevant to outpatient\n",
    "outpatient['ClaimStart_after_ClaimEnd'] = ((outpatient['ClaimStartDt'].notna() & outpatient['ClaimEndDt'].notna()) &\n",
    "                                           (outpatient['ClaimStartDt'] > outpatient['ClaimEndDt'])).astype(int)\n",
    "\n",
    "outpatient['ClaimStart_before_ClaimEnd'] = ((outpatient['ClaimStartDt'].notna() & outpatient['ClaimEndDt'].notna()) &\n",
    "                                            (outpatient['ClaimStartDt'] < outpatient['ClaimEndDt'])).astype(int)  # mostly true\n",
    "\n",
    "outpatient['Future_dates'] = (outpatient[['ClaimStartDt','ClaimEndDt']].gt(today).any(axis=1)).astype(int)\n",
    "\n",
    "outpatient['ClaimStart_before_Now_but_End_missing'] = ((outpatient['ClaimStartDt'].notna() & outpatient['ClaimEndDt'].isna())).astype(int)\n",
    "\n",
    "# conditional suspicious flags:\n",
    "outpatient['ClaimStart_after_ClaimEnd_no_payment'] = ((outpatient['ClaimStart_after_ClaimEnd'] == 1) & (outpatient['any_payment'] == 0)).astype(int)\n",
    "outpatient['Future_dates_no_payment'] = ((outpatient['Future_dates'] == 1) & (outpatient['any_payment'] == 0)).astype(int)\n",
    "\n",
    "# 6) Physician features (same logic as inpatient)\n",
    "phys_cols = ['AttendingPhysician', 'OperatingPhysician', 'OtherPhysician']\n",
    "\n",
    "# freq encoding across all physician columns\n",
    "phys_freq = pd.concat([outpatient[col] for col in phys_cols]).value_counts()\n",
    "for col in phys_cols:\n",
    "    outpatient[col + '_freq'] = outpatient[col].map(phys_freq).fillna(0).astype(int)\n",
    "    outpatient[col + '_presence'] = outpatient[col].notna().astype(int)\n",
    "\n",
    "outpatient['num_physicians'] = outpatient[[col + '_presence' for col in phys_cols]].sum(axis=1)\n",
    "\n",
    "# 7) Diagnosis-level expected-payment modeling (smoothed)\n",
    "# We'll map diag -> smoothed mean of total_payment for claims containing that diag.\n",
    "# Build a long table of ClaimID, diag_code, claim_payment\n",
    "long = outpatient[['ClaimID'] + diag_cols + ['total_payment']].set_index('ClaimID').reset_index()\n",
    "melted = long.melt(id_vars=['ClaimID','total_payment'], value_vars=diag_cols,\n",
    "                   var_name='diag_slot', value_name='diag_code')\n",
    "# clean diag_code\n",
    "melted['diag_code'] = melted['diag_code'].astype(str).str.strip()\n",
    "melted = melted[~melted['diag_code'].str.lower().isin(placeholders)]\n",
    "melted = melted[melted['diag_code'].notna()]\n",
    "\n",
    "# compute diag-level stats\n",
    "diag_stats = (melted.groupby('diag_code')['total_payment']\n",
    "                    .agg(['count', 'mean', 'median'])\n",
    "                    .rename(columns={'mean':'mean_payment', 'median':'median_payment'})\n",
    "                    .reset_index())\n",
    "\n",
    "# smoothing toward global median to stabilise rare codes\n",
    "global_center = melted['total_payment'].median() if len(melted)>0 else 0.0\n",
    "k = 10.0  # prior strength; tuneable\n",
    "diag_stats['smoothed_mean_payment'] = (diag_stats['count'] * diag_stats['mean_payment'] + k * global_center) / (diag_stats['count'] + k)\n",
    "\n",
    "# mapping dicts\n",
    "smoothed_map = diag_stats.set_index('diag_code')['smoothed_mean_payment'].to_dict()\n",
    "median_map = diag_stats.set_index('diag_code')['median_payment'].to_dict()\n",
    "count_map = diag_stats.set_index('diag_code')['count'].to_dict()\n",
    "\n",
    "# map back to outpatient per diag slot\n",
    "for col in diag_cols:\n",
    "    outpatient[col + '_diag_exp_payment'] = outpatient[col].map(smoothed_map).fillna(0.0)\n",
    "    outpatient[col + '_diag_median_payment'] = outpatient[col].map(median_map).fillna(0.0)\n",
    "    outpatient[col + '_diag_count'] = outpatient[col].map(count_map).fillna(0).astype(int)\n",
    "\n",
    "# aggregate diag-derived expectations at claim-level\n",
    "exp_cols = [c + '_diag_exp_payment' for c in diag_cols]\n",
    "med_cols = [c + '_diag_median_payment' for c in diag_cols]\n",
    "cnt_cols = [c + '_diag_count' for c in diag_cols]\n",
    "\n",
    "outpatient['diag_expected_mean_payment'] = outpatient[exp_cols].replace(0, np.nan).mean(axis=1).fillna(0.0)\n",
    "outpatient['diag_expected_median_payment'] = outpatient[med_cols].replace(0, np.nan).median(axis=1).fillna(0.0)\n",
    "outpatient['diag_expected_max_payment'] = outpatient[exp_cols].max(axis=1).fillna(0.0)\n",
    "outpatient['diag_expected_sum_payment'] = outpatient[exp_cols].sum(axis=1).fillna(0.0)\n",
    "outpatient['diag_present_count'] = (outpatient[exp_cols] > 0).sum(axis=1)\n",
    "\n",
    "# ratio features: actual total_payment vs expected\n",
    "outpatient['claim_to_diag_expected_mean'] = np.where(\n",
    "    outpatient['diag_expected_mean_payment'] > 0,\n",
    "    outpatient['total_payment'] / outpatient['diag_expected_mean_payment'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "outpatient['claim_to_diag_expected_max'] = np.where(\n",
    "    outpatient['diag_expected_max_payment'] > 0,\n",
    "    outpatient['total_payment'] / outpatient['diag_expected_max_payment'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# rare-diagnosis flag\n",
    "rare_threshold = 5\n",
    "outpatient['claim_has_rare_diag'] = (outpatient[cnt_cols] > 0).apply(lambda row: any(row < rare_threshold), axis=1).astype(int)\n",
    "\n",
    "# expected vs actual gaps\n",
    "outpatient['expected_vs_actual_gap'] = outpatient['total_payment'] - outpatient['diag_expected_mean_payment']\n",
    "outpatient['expected_vs_actual_pct'] = outpatient['total_payment'] / outpatient['diag_expected_mean_payment'].replace({0: np.nan})\n",
    "\n",
    "# 8) Summaries & quick checks\n",
    "print(\"Outpatient date/anomaly summary:\")\n",
    "date_issue_cols = ['ClaimStart_after_ClaimEnd','Future_dates','ClaimStart_before_ClaimEnd','ClaimStart_after_ClaimEnd_no_payment','Future_dates_no_payment']\n",
    "print(outpatient[date_issue_cols].sum())\n",
    "\n",
    "print(\"\\nTop suspicious outpatient claims by expected_vs_actual_gap:\")\n",
    "print(outpatient.sort_values('expected_vs_actual_gap', ascending=False)\n",
    "                .loc[:, ['ClaimID','Provider','BeneID','total_payment','diag_expected_mean_payment','expected_vs_actual_gap','claim_to_diag_expected_mean']]\n",
    "                .head(20))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#test:\n",
    "\n",
    "\n",
    "\n",
    "### outpatient_test\n",
    "# 1) Parse date columns (safe)\n",
    "date_cols = outpatient_test.columns[outpatient_test.columns.str.contains('Dt|Date', case=False)]\n",
    "for col in date_cols:\n",
    "    outpatient_test[col] = pd.to_datetime(outpatient_test[col], errors='coerce')\n",
    "\n",
    "today = pd.Timestamp.today()\n",
    "\n",
    "# 2) Diagnosis / Procedure presence flags & counts\n",
    "diag_cols = [f'ClmDiagnosisCode_{i}' for i in range(1, 11)]\n",
    "procedure_cols = [f'ClmProcedureCode_{i}' for i in range(1, 7)]\n",
    "\n",
    "# presence flags (1 if present, 0 if null/empty/placeholder)\n",
    "placeholders = {'nan', 'none', 'unknown', 'na', '', 'nan.'}\n",
    "for col in diag_cols:\n",
    "    outpatient_test[col] = outpatient_test[col].astype(str).str.strip().replace({c: np.nan for c in placeholders})\n",
    "    outpatient_test[col + '_present'] = outpatient_test[col].notna().astype(int)\n",
    "\n",
    "for col in procedure_cols:\n",
    "    outpatient_test[col] = outpatient_test[col].astype(str).str.strip().replace({c: np.nan for c in placeholders})\n",
    "    outpatient_test[col + '_present'] = outpatient_test[col].notna().astype(int)\n",
    "\n",
    "# totals per claim\n",
    "outpatient_test['num_diagnoses'] = outpatient_test[[c + '_present' for c in diag_cols]].sum(axis=1)\n",
    "outpatient_test['num_procedures'] = outpatient_test[[c + '_present' for c in procedure_cols]].sum(axis=1)\n",
    "\n",
    "# 3) Safe numeric payments\n",
    "outpatient_test['DeductibleAmtPaid'] = outpatient_test['DeductibleAmtPaid'].fillna(0).astype(float)\n",
    "outpatient_test['InscClaimAmtReimbursed'] = outpatient_test['InscClaimAmtReimbursed'].fillna(0).astype(float)\n",
    "outpatient_test['total_payment'] = outpatient_test['DeductibleAmtPaid'] + outpatient_test['InscClaimAmtReimbursed']\n",
    "\n",
    "# payment flags\n",
    "outpatient_test['patient_paid'] = (outpatient_test['DeductibleAmtPaid'] > 0).astype(int)\n",
    "outpatient_test['insurer_paid'] = (outpatient_test['InscClaimAmtReimbursed'] > 0).astype(int)\n",
    "outpatient_test['any_payment'] = ((outpatient_test['patient_paid'] == 1) | (outpatient_test['insurer_paid'] == 1)).astype(int)\n",
    "\n",
    "# 4) Duration feature (days)\n",
    "outpatient_test['claim_duration_days'] = (outpatient_test['ClaimEndDt'] - outpatient_test['ClaimStartDt']).dt.days\n",
    "outpatient_test['claim_duration_days_nonzero'] = outpatient_test['claim_duration_days'].apply(lambda x: x if (pd.notna(x) and x >= 1) else 1.0)\n",
    "\n",
    "# 5) Date anomalies relevant to outpatient_test\n",
    "outpatient_test['ClaimStart_after_ClaimEnd'] = ((outpatient_test['ClaimStartDt'].notna() & outpatient_test['ClaimEndDt'].notna()) &\n",
    "                                           (outpatient_test['ClaimStartDt'] > outpatient_test['ClaimEndDt'])).astype(int)\n",
    "\n",
    "outpatient_test['ClaimStart_before_ClaimEnd'] = ((outpatient_test['ClaimStartDt'].notna() & outpatient_test['ClaimEndDt'].notna()) &\n",
    "                                            (outpatient_test['ClaimStartDt'] < outpatient_test['ClaimEndDt'])).astype(int)\n",
    "\n",
    "outpatient_test['Future_dates'] = (outpatient_test[['ClaimStartDt','ClaimEndDt']].gt(today).any(axis=1)).astype(int)\n",
    "\n",
    "outpatient_test['ClaimStart_before_Now_but_End_missing'] = ((outpatient_test['ClaimStartDt'].notna() & outpatient_test['ClaimEndDt'].isna())).astype(int)\n",
    "\n",
    "# conditional suspicious flags:\n",
    "outpatient_test['ClaimStart_after_ClaimEnd_no_payment'] = ((outpatient_test['ClaimStart_after_ClaimEnd'] == 1) & (outpatient_test['any_payment'] == 0)).astype(int)\n",
    "outpatient_test['Future_dates_no_payment'] = ((outpatient_test['Future_dates'] == 1) & (outpatient_test['any_payment'] == 0)).astype(int)\n",
    "\n",
    "# 6) Physician features\n",
    "phys_cols = ['AttendingPhysician', 'OperatingPhysician', 'OtherPhysician']\n",
    "\n",
    "# freq encoding\n",
    "phys_freq = pd.concat([outpatient_test[col] for col in phys_cols]).value_counts()\n",
    "for col in phys_cols:\n",
    "    outpatient_test[col + '_freq'] = outpatient_test[col].map(phys_freq).fillna(0).astype(int)\n",
    "    outpatient_test[col + '_presence'] = outpatient_test[col].notna().astype(int)\n",
    "\n",
    "outpatient_test['num_physicians'] = outpatient_test[[col + '_presence' for col in phys_cols]].sum(axis=1)\n",
    "\n",
    "# 7) Diagnosis-level modeling\n",
    "long = outpatient_test[['ClaimID'] + diag_cols + ['total_payment']].set_index('ClaimID').reset_index()\n",
    "melted = long.melt(id_vars=['ClaimID','total_payment'], value_vars=diag_cols,\n",
    "                   var_name='diag_slot', value_name='diag_code')\n",
    "\n",
    "melted['diag_code'] = melted['diag_code'].astype(str).str.strip()\n",
    "melted = melted[~melted['diag_code'].str.lower().isin(placeholders)]\n",
    "melted = melted[melted['diag_code'].notna()]\n",
    "\n",
    "diag_stats = (melted.groupby('diag_code')['total_payment']\n",
    "                    .agg(['count', 'mean', 'median'])\n",
    "                    .rename(columns={'mean':'mean_payment', 'median':'median_payment'})\n",
    "                    .reset_index())\n",
    "\n",
    "global_center = melted['total_payment'].median() if len(melted)>0 else 0.0\n",
    "k = 10.0\n",
    "diag_stats['smoothed_mean_payment'] = (diag_stats['count'] * diag_stats['mean_payment'] + k * global_center) / (diag_stats['count'] + k)\n",
    "\n",
    "smoothed_map = diag_stats.set_index('diag_code')['smoothed_mean_payment'].to_dict()\n",
    "median_map = diag_stats.set_index('diag_code')['median_payment'].to_dict()\n",
    "count_map = diag_stats.set_index('diag_code')['count'].to_dict()\n",
    "\n",
    "for col in diag_cols:\n",
    "    outpatient_test[col + '_diag_exp_payment'] = outpatient_test[col].map(smoothed_map).fillna(0.0)\n",
    "    outpatient_test[col + '_diag_median_payment'] = outpatient_test[col].map(median_map).fillna(0.0)\n",
    "    outpatient_test[col + '_diag_count'] = outpatient_test[col].map(count_map).fillna(0).astype(int)\n",
    "\n",
    "# aggregate\n",
    "exp_cols = [c + '_diag_exp_payment' for c in diag_cols]\n",
    "med_cols = [c + '_diag_median_payment' for c in diag_cols]\n",
    "cnt_cols = [c + '_diag_count' for c in diag_cols]\n",
    "\n",
    "outpatient_test['diag_expected_mean_payment'] = outpatient_test[exp_cols].replace(0, np.nan).mean(axis=1).fillna(0.0)\n",
    "outpatient_test['diag_expected_median_payment'] = outpatient_test[med_cols].replace(0, np.nan).median(axis=1).fillna(0.0)\n",
    "outpatient_test['diag_expected_max_payment'] = outpatient_test[exp_cols].max(axis=1).fillna(0.0)\n",
    "outpatient_test['diag_expected_sum_payment'] = outpatient_test[exp_cols].sum(axis=1).fillna(0.0)\n",
    "outpatient_test['diag_present_count'] = (outpatient_test[exp_cols] > 0).sum(axis=1)\n",
    "\n",
    "outpatient_test['claim_to_diag_expected_mean'] = np.where(\n",
    "    outpatient_test['diag_expected_mean_payment'] > 0,\n",
    "    outpatient_test['total_payment'] / outpatient_test['diag_expected_mean_payment'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "outpatient_test['claim_to_diag_expected_max'] = np.where(\n",
    "    outpatient_test['diag_expected_max_payment'] > 0,\n",
    "    outpatient_test['total_payment'] / outpatient_test['diag_expected_max_payment'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "rare_threshold = 5\n",
    "outpatient_test['claim_has_rare_diag'] = (outpatient_test[cnt_cols] > 0).apply(lambda row: any(row < rare_threshold), axis=1).astype(int)\n",
    "\n",
    "outpatient_test['expected_vs_actual_gap'] = outpatient_test['total_payment'] - outpatient_test['diag_expected_mean_payment']\n",
    "outpatient_test['expected_vs_actual_pct'] = outpatient_test['total_payment'] / outpatient_test['diag_expected_mean_payment'].replace({0: np.nan})\n",
    "\n",
    "# 8) Summaries\n",
    "print(\"Outpatient_test date/anomaly summary:\")\n",
    "date_issue_cols = ['ClaimStart_after_ClaimEnd','Future_dates','ClaimStart_before_ClaimEnd','ClaimStart_after_ClaimEnd_no_payment','Future_dates_no_payment']\n",
    "print(outpatient_test[date_issue_cols].sum())\n",
    "\n",
    "print(\"\\nTop suspicious outpatient_test claims by expected_vs_actual_gap:\")\n",
    "print(outpatient_test.sort_values('expected_vs_actual_gap', ascending=False)\n",
    "                .loc[:, ['ClaimID','Provider','BeneID','total_payment','diag_expected_mean_payment','expected_vs_actual_gap','claim_to_diag_expected_mean']]\n",
    "                .head(20))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c75bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inpatient.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab798019",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate\n",
    "# Example aggregations – add more as needed\n",
    "inpatient_provider = inpatient.groupby('Provider').agg({\n",
    "    'total_payment': ['mean', 'sum', 'max', 'median'],\n",
    "    'num_diagnoses': ['mean', 'max'],\n",
    "    'num_procedures': ['mean', 'max'],\n",
    "    'patient_paid': 'mean',\n",
    "    'insurer_paid': 'mean',\n",
    "    'claim_has_rare_diag': 'mean'\n",
    "})\n",
    "\n",
    "# flatten multi-level columns\n",
    "inpatient_provider.columns = ['inp_' + '_'.join(col) for col in inpatient_provider.columns]\n",
    "inpatient_provider.reset_index(inplace=True)\n",
    "\n",
    "#test:\n",
    "\n",
    "#aggregate\n",
    "# Example aggregations – add more as needed\n",
    "inpatient_test_provider = inpatient_test.groupby('Provider').agg({\n",
    "    'total_payment': ['mean', 'sum', 'max', 'median'],\n",
    "    'num_diagnoses': ['mean', 'max'],\n",
    "    'num_procedures': ['mean', 'max'],\n",
    "    'patient_paid': 'mean',\n",
    "    'insurer_paid': 'mean',\n",
    "    'claim_has_rare_diag': 'mean'\n",
    "})\n",
    "\n",
    "# flatten multi-level columns\n",
    "inpatient_test_provider.columns = ['inp_' + '_'.join(col) for col in inpatient_test_provider.columns]\n",
    "inpatient_test_provider.reset_index(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687350d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outpatient_provider = outpatient.groupby('Provider').agg({\n",
    "    'total_payment': ['mean', 'sum', 'max', 'median'],\n",
    "    'num_diagnoses': ['mean', 'max'],\n",
    "    'num_procedures': ['mean', 'max'],\n",
    "    'patient_paid': 'mean',\n",
    "    'insurer_paid': 'mean',\n",
    "    'claim_duration_days': ['mean', 'max'],\n",
    "    'claim_to_diag_expected_mean': 'mean',\n",
    "    'claim_has_rare_diag': 'mean'\n",
    "})\n",
    "\n",
    "outpatient_provider.columns = ['out_' + '_'.join(col) for col in outpatient_provider.columns]\n",
    "outpatient_provider.reset_index(inplace=True)\n",
    "\n",
    "#test:\n",
    "\n",
    "outpatient_test_provider = outpatient_test.groupby('Provider').agg({\n",
    "    'total_payment': ['mean', 'sum', 'max', 'median'],\n",
    "    'num_diagnoses': ['mean', 'max'],\n",
    "    'num_procedures': ['mean', 'max'],\n",
    "    'patient_paid': 'mean',\n",
    "    'insurer_paid': 'mean',\n",
    "    'claim_duration_days': ['mean', 'max'],\n",
    "    'claim_to_diag_expected_mean': 'mean',\n",
    "    'claim_has_rare_diag': 'mean'\n",
    "})\n",
    "\n",
    "outpatient_test_provider.columns = ['out_' + '_'.join(col) for col in outpatient_test_provider.columns]\n",
    "outpatient_test_provider.reset_index(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599e1f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge bene data to both claim tables\n",
    "inpatient_bene = inpatient.merge(benf, on='BeneID', how='left')\n",
    "outpatient_bene = outpatient.merge(benf, on='BeneID', how='left')\n",
    "\n",
    "# now aggregate per provider\n",
    "beneficiary_provider = pd.concat([inpatient_bene, outpatient_bene]).groupby('Provider').agg({\n",
    "    'ChronicCond_Alzheimer': 'mean',\n",
    "    'ChronicCond_Heartfailure': 'mean',\n",
    "    'ChronicCond_Cancer': 'mean',\n",
    "    'DOB': 'count'   # number of unique patients served\n",
    "})\n",
    "\n",
    "beneficiary_provider.rename(columns={'DOB': 'num_patients'}, inplace=True)\n",
    "beneficiary_provider.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "#test:\n",
    "\n",
    "# merge bene data to both claim tables\n",
    "inpatient_test_bene = inpatient_test.merge(benf, on='BeneID', how='left')\n",
    "outpatient_test_bene = outpatient_test.merge(benf, on='BeneID', how='left')\n",
    "\n",
    "# now aggregate per provider\n",
    "beneficiary_test_provider = pd.concat([inpatient_test_bene, outpatient_test_bene]).groupby('Provider').agg({\n",
    "    'ChronicCond_Alzheimer': 'mean',\n",
    "    'ChronicCond_Heartfailure': 'mean',\n",
    "    'ChronicCond_Cancer': 'mean',\n",
    "    'DOB': 'count'   # number of unique patients served\n",
    "})\n",
    "\n",
    "beneficiary_test_provider.rename(columns={'DOB': 'num_patients'}, inplace=True)\n",
    "beneficiary_test_provider.reset_index(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898dbc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa755353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with labels\n",
    "train_labels = pd.read_csv('../data/Train-1542865627584.csv')\n",
    "train_final = train_labels.copy()\n",
    "\n",
    "# merge inpatient\n",
    "train_final = train_final.merge(inpatient_provider, on='Provider', how='left')\n",
    "\n",
    "# merge outpatient\n",
    "train_final = train_final.merge(outpatient_provider, on='Provider', how='left')\n",
    "\n",
    "# merge beneficiary-based features\n",
    "train_final = train_final.merge(beneficiary_provider, on='Provider', how='left')\n",
    "\n",
    "# fill missing values (safe approach)\n",
    "train_final = train_final.fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "#test:\n",
    "\n",
    "\n",
    "# start with labels\n",
    "\n",
    "test_final = test_id.copy()\n",
    "\n",
    "# merge inpatient\n",
    "test_final = test_final.merge(inpatient_test_provider, on='Provider', how='left')\n",
    "\n",
    "# merge outpatient\n",
    "test_final = test_final.merge(outpatient_test_provider, on='Provider', how='left')\n",
    "\n",
    "# merge beneficiary-based features\n",
    "test_final = test_final.merge(beneficiary_test_provider, on='Provider', how='left')\n",
    "\n",
    "# fill missing values (safe approach)\n",
    "test_final = test_final.fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb538d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train_final.columns:\n",
    "    dtype = train_final[col].dtype\n",
    "    \n",
    "    if pd.api.types.is_numeric_dtype(train_final[col]):\n",
    "        continue  # skip numeric columns\n",
    "    elif pd.api.types.is_datetime64_any_dtype(train_final[col]):\n",
    "        print(f\"{col}: datetime → should be encoded (e.g., duration, day/month/year)\")\n",
    "    elif pd.api.types.is_object_dtype(train_final[col]):\n",
    "        print(f\"{col}: categorical → should be encoded (e.g., one-hot or label encoding)\")\n",
    "    else:\n",
    "        print(f\"{col}: unknown type {dtype} → check manually\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7811a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Encode PotentialFraud as 0/1\n",
    "train_final['PotentialFraud'] = train_final['PotentialFraud'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Check the result\n",
    "train_final.head(1)\n",
    "\n",
    "\n",
    "#test:\n",
    "\n",
    "\n",
    "\n",
    "# Check the result\n",
    "test_final.head(1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8745cb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select columns to aggregate\n",
    "agg_columns = [\n",
    "    \"out_claim_duration_days_mean\",\n",
    "    \"out_claim_duration_days_max\",\n",
    "    \"out_claim_to_diag_expected_mean_mean\",\n",
    "    \"out_claim_has_rare_diag_mean\",\n",
    "    \"ChronicCond_Alzheimer\",\n",
    "    \"ChronicCond_Heartfailure\",\n",
    "    \"ChronicCond_Cancer\",\n",
    "    \"num_patients\"\n",
    "]\n",
    "\n",
    "# Check that all columns exist\n",
    "for col in agg_columns + [\"Provider\"]:\n",
    "    if col not in train_final.columns:\n",
    "        raise KeyError(f\"Missing column in train_final: {col}\")\n",
    "    if col not in test_final.columns:\n",
    "        raise KeyError(f\"Missing column in test_final: {col}\")\n",
    "\n",
    "#TRAIN provider-level aggregation\n",
    "train_provider = train_final.groupby(\"Provider\").agg({\n",
    "    \"out_claim_duration_days_mean\": \"mean\",\n",
    "    \"out_claim_duration_days_max\": \"max\",\n",
    "    \"out_claim_to_diag_expected_mean_mean\": \"mean\",\n",
    "    \"out_claim_has_rare_diag_mean\": \"mean\",\n",
    "    \"ChronicCond_Alzheimer\": \"mean\",\n",
    "    \"ChronicCond_Heartfailure\": \"mean\",\n",
    "    \"ChronicCond_Cancer\": \"mean\",\n",
    "    \"num_patients\": \"max\"    # Prevent double-count & duplication across claims\n",
    "}).reset_index()\n",
    "\n",
    "#TEST provider-level aggregation\n",
    "test_provider = test_final.groupby(\"Provider\").agg({\n",
    "    \"out_claim_duration_days_mean\": \"mean\",\n",
    "    \"out_claim_duration_days_max\": \"max\",\n",
    "    \"out_claim_to_diag_expected_mean_mean\": \"mean\",\n",
    "    \"out_claim_has_rare_diag_mean\": \"mean\",\n",
    "    \"ChronicCond_Alzheimer\": \"mean\",\n",
    "    \"ChronicCond_Heartfailure\": \"mean\",\n",
    "    \"ChronicCond_Cancer\": \"mean\",\n",
    "    \"num_patients\": \"max\"\n",
    "}).reset_index()\n",
    "\n",
    "print(train_provider.shape, test_provider.shape)\n",
    "train_provider.head(), test_provider.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2b74cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge:\n",
    "train_final = train_final.merge(train_provider, on=\"Provider\", how=\"left\")\n",
    "test_final = test_final.merge(test_provider, on=\"Provider\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcda854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final = train_final.drop(columns=['Provider'])\n",
    "test_final = test_final.drop(columns=['Provider'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
